#okay, so far what have we done?
# we have modified the code to run with gazebo classic instead of ignition and the reason is ignition is so bad, I had to work with the raw sdf files to add the plugins and the lidar plugin was very tiring to add, it was time consuming
# and I had to run into loops of debugging
#now that we are good to go, so far we are able to run it in gazebo and rviz2, then control it with the teleop_twist_keyboard package 
#the include tag in the robot.urdf.xacro file is not really working, it just takes the main core file and dont take the others. 
#I had to add the lidar plugins manually 
#the lidar work this way: you add the lidar joint in the core.xacro and then in the gazebo tag you have to add the sensor and the plugin things
#it was not working initially and this is due to some deprecation, <argument>~/out:=scan</argument> is replaced with <remapping>~/out:=scan</remapping>
 # <visualise> tag should be true and not false if you want to see the rays in gazebo
#thats it for gazebo, here is the commands steps
# 1. ros2 launch articubot_one launch_sim.launch.py
# 2. ros2 run teleop_twist_keyboard teleop_twist_keyboard 
# 3. ros2 run rviz2 

# 4. add the robot model and the laser scan
# 5. add the laser scan topic and the robot model
# 6. main frame is odom



20/04/2025

I have added the camera system and it ran smoothly, I have also added the depth camera system and it ran smoothly as well, the main difference between both is the depth camera will have plugin type of "depth" and camera controller extra 
tags like the min fram and max frame.

the theory is okay but it definitely needs to have more study, recommendation is to rewatch the video when he explains the theory and read documentations regarding that topic 


depth camera plugin documentation : https://classic.gazebosim.org/tutorials?tut=ros_depth_camera
normal camera plugin documentation : https://classic.gazebosim.org/tutorials?tut=ros_gzplugins

gazebo classic is simply better, more direct and easier to handle gazebo ignition. 


what are the commands, 

same as before, launch_sim.py command, then rviz2. in rviz2 image topic should be added to see the results, and also rqt-image-view, now you run ros2 run rqt_image_view rqt_image_view this will show the uncompressed image and the compresed
this is needed as rviz is not able to show the uncompressed images from the camera. 

IRL, the following is used so that you can republish the compressed images as uncompressed in a another topic, 
    ros2 run image_transport republish compressed raw --ros-args -r in/compressed:=/camera/image_raw/compresed -r out:=/camera/image_raw/uncompressed 

this will take the compressed image published by gazebo and then uncompress it to the topic, camera/image_raw/uncompressed 
useful if you want to send the data, uncompress it over the network and uncompress it on the other end.


4/05/2025 and 6/05/2025

the reason there is a gap in the dates compared to before and two days is I got sick, I got bacterial infected and was dying, dont eat from outside much and dont be over stressed!

today we are adding the ros2 control to the system, this is done first by downloading the packages for the ros2 control and the ros2 version and the ros2 control for the gazebo, 
after that we add the ros2 control hardware setup, this is done by adding the ros2_contorl tags to the urdf file. as usual the original way is to make a separate file and include in the robot.urdf.xacro but this failed miserably 
for me, the only clue I found was that xacro is not able to include the files other than the main urdf files. 
anyways, in the urdf file we add the tags for the hardware control,there we specify in the hardware tags what are the joints that are going to be under the ros2 control, which are the wheels joints. 
then we decide the command interface, which is basically what we are going to control, some robots got their command interface to be the torque, some got velocity and position, for our robot its velocity,
in the command interface we till ros how much of range we need for the control, for us its from -10 to 10

finally you got the state interface, the command interface is a 'read and write' interface, but the state interface is only a 'read' interface, meaning that we can just read the thing without contorl it, for our case we are
going to read the position and the velocity of the joints.

finally, the gazebo tags for the ros2 control, basically we tell gazebo that we are using a ros2 control and to read the hardware control tags from the above, this is done by reading the main dish of ros2 contorl, which is the yaml file
that contains all the parameters for ros2 control.

 the yaml file, which contains all the parameters for the controllers we want to implement, we first start with the controller manager, how much rate we are going to send/recieve the data, what are the controllers. Then after we
 write the details of each controller we have, for us it is the diff_drive, we specify the publish rate, which should be same as the main controller, then what are the joints that are going to be subjected to the diff drive, 
 there are bunch of more controllers, but they are not needed to be uncommented nor used for our project. 

 now comes the biggest bug I have met, after I added the controller and wanted to simulate it in gazebo, when I press the keyboard to move, it just jumps chaotically, no restrain, as if it is a tennis ball that is subjected to 
 ronaldo's kick, just pure chaos.

 I could not really findd the problem, before the controller the robot is okay, after the controller its more uncontrolled than before, I tried to change the controller settings and the parameters but there was no use, I have also 
 wrote about this issue in the discussion forums, but there is no response obviously.

 the only one who helped me was dr Zaki, my mentor for ros2, he changed the weights and the inertia, he also changed the diff_drive plugin limits, which I didnt really think of, and viola! it is working nice now! 

 the only thing remains for now is that when I open rviz2, it appears like the robot is there in two places at the same time, so it kind of glitches, I dont know the cause, but I will look into it. 

 okay, one thing I have figured out, when I initiate the controllers, the rviz robot starts tweaking out.

 in the video, he upgraded the robot to be the similar to the one in real life, but I grew attached to the current one and the I finaaally fixed everything with it, so I dont think I will changing it.

 okay, done, the problem was rviz was taking tfs at the same time, thus glitching. the solution is quite, turn off the odom tf in the controller yaml file.
 this is the command :      enable_odom_tf: false

 this will make things stable. 


 one more thing I have added, which is recording and listening to the position and the velocity of the joints when the simulation is running, this can be done in two ways. 
 before anything, the state broadcaster controller is not commented out anymore and thus is able to read the state of the joints.
 
 the first way is just listening to the data, this is done by listening, ros2 topic echo /joint_states 

 this will literally give you the live data for the robot. however it is not professional, as you can just listen. 

 the second way, is to use ros2bag to generate a file containing those data, ros2 bag record /joint_states /odom -o my_robot_data

 this will create the file "my_robot_data" and have the file of the joint_states in it. later on we can just convert to .csv or pdf.

most of the videos are for the hardware, like adding the joysticks and stuff, I am not going to watch it now tbh, but I will watch them later.

 now, it is time for the main dish for this big project, the nav2 and SLAM. 


 12/05/25 

 today I am starting with SLAM, basically I did that yesterday but because the installation for slam took too long, I slept. 

 today, I found a problem while following the video, speaking of the videos, I have watched most of the vids before starting today and they are basically for the real life parts, the only thing that I got interested in was the joystick
 stuff, but I dont have a joy stick soooo.

 so the problem is was that my robot, in gazebo when it is in origin, it moves to the left, that was weird as I didnt press any key and it was super slow, but I adjusted the weights of the wheels to 5, and it is static now, hopefully it remains.

 now moving on with slam, I am able to generate the slam map (yay)

 but there is a problem, when my robot is moving and everything is okay, it suddenly go two-wheeler, I dont konw why, but it looks ridiculous and it messes up the lidar reading I changed the caster wheel weight, from 00.01 to 0.1 but no use
 I think of either increase the weight of the chassis and the caster wheel. 
 
 update: it is working just fine, and the map generated in rviz is just, beautiful.

 we started localisation with AMCL

 a note, this needs to be STUDIED, THOROUGHLY.

 it didnt work at first, but in rviz, map node, under topic, change durability policy to transient local


 this is pretty tough at the moment, as there something I noticed, I dont have a pre made world in gazebo, which means everytime I run the whole SLAM thing will make it so that I start from scratch, generate images of the map from scratch
 and so on, so I think it would be better to make a prebuild world then rerun the whole thing.

 aight, luckily for me, I have installed slam and nav2, thus I have the world for slam, the whole grid, I added it, adjusted the location of it, and saved the world, notice: dont delete the robot and then save the world, it will freeze,
 instead, save it with the bot, then close it and go to the .sdf file and delete the model from there, and in the command, you should add the absolute path of the world. 

 this is the command for running the world : 
 
  ros2 launch articubot_one launch_sim.launch.py world:=/home/ubuntu/ros2_ws/src/articubot_one/worlds/obstacles.world

 now time to continue with our process.

 okay, everything is running pretty smooth and pretty good, there are lots of tabs that we are using, but basically it because we have two algs we run, first is the online_async and the second is the amcl, the Adaptive Monte-Carlo Localizer.

first of, the online_async  which basically means we are making it live data stream instead of recorded logs, and async is for processing the latest scans to ovoid obstacles.

we run our launch command, then rviz annd the teleop_twist_keyboard

then this command : 

ros2 run nav2_map_server map_server --ros-args -p yaml_filename:=my_map_save.yaml -p use_sim_time:=true

then this command : 

ros2 run nav2_util lifecycle_bringup map_server

in rviz, we run the robot so that it can make the map of the surroundings, then we add a slam toolbox panel, this appears after installing the nav2 and slam toolbox stuff

we save the map, as well as serialise the map, the first option will create pgm. a pic of the map, and yaml file, the second one is creating a data file and posegraph file, those are usedd in localisation later on.


UPDATE: If you're on humble or newer, please note that "params_file" has changed to "slam_params_file". not sure what is that tbh
okay, this is for the online_async to load the map, I didnt have the issue, even tho it required for humble and above....


oh, before that, we need to copy a yaml file from the nav2 stack, this is the commandd for it : 
cp /opt/ros/humble/share/slam_toolbox/config/mapper_params_online_async.yaml ros2_ws/src/articubot_one/config/

you need to be in your main blank terminnal for that.

then continuiung, after that, we stop the commands, then we change the mapper_params_online_async file, we change the mapping to localisation and then 
we add the absolute path for the data file, without the extension in it.

then we rerun rviz and gazebo, and in rviz the map should be loaded and ready

localisation and mapping in general is releated to the fact that the rviz and gazebo are in sync, the odom fram is not in sync 
with the origin, thus inaccurate, but we have to use basae_footprint, then in the nav2 yaml file it takes, that is a 
joint on top of the base link that doesnt do much. 

AMCL 


now with amcl, same procedure, in nav2 so far you need two main commands : 

ros2 launch slam_toolbox online_async_launch.py  params_file:=./src/articubot_one/config/mapper_params_online_async.yaml use_sim_time:=true

then 

 ros2 run nav2_map_server map_server --ros-args -p yaml_filename:=my_map_save.yaml -p use_sim_time:=true 

 then 

 ros2 run nav2_util lifecycle_bringup amcl 


or with the asml

ros2 run nav2_amcl amcl --ros-args -p use_sim_time:=true

then 
ros2 run nav2_util lifecycle_bringup amcl 



all that while rviz2 is running

for me, the online_async is betterr than amcl, its much more smoother.

---------------------------------------------------------------------------------------------

done.  [^_^]



so far, nav2 is kinda easy, just a lot to run at the same time.

I had two problems : 

problem 1: I have copied the localisation and navigation files from both the slam_toolbox and nav2 files, this is so that I can run them using articubot_one name, but it didnt work, it cant find the files
problem 2: I have added the joystick file, but when I added it to the launch file, it didnt work, and crashed, so I removed it from the launch file but the files and node for launch are there.

both the problems pose to issue to me, as the robot and the nav2 stack is able to run smoothly. just with more bit of a work than usual.


now, time to start the development process.

nav2, we need some installations to do, which is twist_mux, this is a node where it can take multiple cmd velocity and give out a single one, for this project it is 
made into a joystick and cmd_vel

then we add the yaml file for it, copy it from github, it had priority joystick 100 which is top priority and navigationn topic which is 10

then we go workspace and run this 


ros2 run twist_mux twist_mux --ros-args --params-file /home/ubuntu/ros2_ws/src/articubot_one/config/twist_mux.yaml -r cmd_vel_out:=diff_cont/cmd_vel_unstamped

of course we run also gazebo and rviz2

gazebo command: 

ros2 launch articubot_one launch_sim.launch.py world:=/home/ubuntu/ros2_ws/src/articubot_one/worlds/obstacles.world

teleop_twist_keyboard command :

ros2 run teleop_twist_keyboard teleop_twist_keyboard --ros-args -r /cmd_vel:=/diff_cont/cmd_vel_unstamped




then we run slam_toolbox  using this command 

ros2 launch slam_toolbox online_async_launch.py  slam_params_file:=./src/articubot_one/config/mapper_params_online_async.yaml use_sim_time:=true

this is the same toolbox command from before, this is so that we can make a map, we can either load it or make the map oursellves.


of course dont forget to run the teleop_twist_keyboard command 

then in a new tab, we run the nav2 package using this 

ros2 launch nav2_bringup navigation_launch.py use_sim_time:=true

then, in rviz, we add a new map, and set the topic to global_costmap/costmap and the color to costmap. and you get the map 

then we press 2d goal pose, and press anywhere in the map, and it goes there....

when you take over with the keyboard it lets you do it. 

 ladies and gentlemen, this is nav2.









 now with the AMCL 

 we follow the same steps from before, till the twist_mux and teleop_twist_keyboard then instead of the slam_toolbox we run  this instead

ros2 launch nav2_bringup localization_launch.py map:=/home/ubuntu/ros2_ws/src/articubot_one/my_map_save.yaml use_sim_time:=true

 we set the inital pose in rviz2, which is the fixed frame btw, to map. specify the 2d pose estimate

 then add the map with all the settings from before, keep the topic same, map.


after we run the commands we also run this command 

ros2 launch articubot_one navigation_launch.py use_sim_time:=true map_subscribe_transient_local:=true

this is for nav2 to start up and see the map

in rviz we do the smae thing in map. 


now try adding a cube in front of the robot, ofcourse make it smaller to it can fit the area, you see the map in rviz update in real time that it came in.


use 2d goal pose and then select somewhere you want to go to, it will work.

================================================================================================================================================================
================================================================================================================================================================


this is it, this project is unofficialy done, the only left are the camera, but nav2 is added to the robot. 

total time : around 3 months 

this was a journey, literally was feeling bad when I finished the video, well not bad, just empty....


(/≧▽≦)/ 




02/06/25



Im finally able to do this again, I could not continue the development last week due to me going to the embassy on monday and thus it made it hard on me to use ubuntu because it is too slow



for today, I finally fixed the issue that has been nagging with me, the ball_tracker package that is used was not used properly with the colconn build, for that to change, you have to change the config file in the package and change
the - to _

