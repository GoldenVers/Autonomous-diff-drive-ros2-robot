#okay, so far what have we done?
# we have modified the code to run with gazebo classic instead of ignition and the reason is ignition is so bad, I had to work with the raw sdf files to add the plugins and the lidar plugin was very tiring to add, it was time consuming
# and I had to run into loops of debugging
#now that we are good to go, so far we are able to run it in gazebo and rviz2, then control it with the teleop_twist_keyboard package 
#the include tag in the robot.urdf.xacro file is not really working, it just takes the main core file and dont take the others. 
#I had to add the lidar plugins manually 
#the lidar work this way: you add the lidar joint in the core.xacro and then in the gazebo tag you have to add the sensor and the plugin things
#it was not working initially and this is due to some deprecation, <argument>~/out:=scan</argument> is replaced with <remapping>~/out:=scan</remapping>
 # <visualise> tag should be true and not false if you want to see the rays in gazebo
#thats it for gazebo, here is the commands steps
# 1. ros2 launch articubot_one launch_sim.launch.py
# 2. ros2 run teleop_twist_keyboard teleop_twist_keyboard 
# 3. ros2 run rviz2 

# 4. add the robot model and the laser scan
# 5. add the laser scan topic and the robot model
# 6. main frame is odom



20/04/2025

I have added the camera system and it ran smoothly, I have also added the depth camera system and it ran smoothly as well, the main difference between both is the depth camera will have plugin type of "depth" and camera controller extra 
tags like the min fram and max frame.

the theory is okay but it definitely needs to have more study, recommendation is to rewatch the video when he explains the theory and read documentations regarding that topic 


depth camera plugin documentation : https://classic.gazebosim.org/tutorials?tut=ros_depth_camera
normal camera plugin documentation : https://classic.gazebosim.org/tutorials?tut=ros_gzplugins

gazebo classic is simply better, more direct and easier to handle gazebo ignition. 


what are the commands, 

same as before, launch_sim.py command, then rviz2. in rviz2 image topic should be added to see the results, and also rqt-image-view, now you run ros2 run rqt_image_view rqt_image_view this will show the uncompressed image and the compresed
this is needed as rviz is not able to show the uncompressed images from the camera. 

IRL, the following is used so that you can republish the compressed images as uncompressed in a another topic, 
    ros2 run image_transport republish compressed raw --ros-args -r in/compressed:=/camera/image_raw/compresed -r out:=/camera/image_raw/uncompressed 

this will take the compressed image published by gazebo and then uncompress it to the topic, camera/image_raw/uncompressed 
useful if you want to send the data, uncompress it over the network and uncompress it on the other end.


4/05/2025 and 6/05/2025

the reason there is a gap in the dates compared to before and two days is I got sick, I got bacterial infected and was dying, dont eat from outside much and dont be over stressed!

today we are adding the ros2 control to the system, this is done first by downloading the packages for the ros2 control and the ros2 version and the ros2 control for the gazebo, 
after that we add the ros2 control hardware setup, this is done by adding the ros2_contorl tags to the urdf file. as usual the original way is to make a separate file and include in the robot.urdf.xacro but this failed miserably 
for me, the only clue I found was that xacro is not able to include the files other than the main urdf files. 
anyways, in the urdf file we add the tags for the hardware control,there we specify in the hardware tags what are the joints that are going to be under the ros2 control, which are the wheels joints. 
then we decide the command interface, which is basically what we are going to control, some robots got their command interface to be the torque, some got velocity and position, for our robot its velocity,
in the command interface we till ros how much of range we need for the control, for us its from -10 to 10

finally you got the state interface, the command interface is a 'read and write' interface, but the state interface is only a 'read' interface, meaning that we can just read the thing without contorl it, for our case we are
going to read the position and the velocity of the joints.

finally, the gazebo tags for the ros2 control, basically we tell gazebo that we are using a ros2 control and to read the hardware control tags from the above, this is done by reading the main dish of ros2 contorl, which is the yaml file
that contains all the parameters for ros2 control.

 the yaml file, which contains all the parameters for the controllers we want to implement, we first start with the controller manager, how much rate we are going to send/recieve the data, what are the controllers. Then after we
 write the details of each controller we have, for us it is the diff_drive, we specify the publish rate, which should be same as the main controller, then what are the joints that are going to be subjected to the diff drive, 
 there are bunch of more controllers, but they are not needed to be uncommented nor used for our project. 

 now comes the biggest bug I have met, after I added the controller and wanted to simulate it in gazebo, when I press the keyboard to move, it just jumps chaotically, no restrain, as if it is a tennis ball that is subjected to 
 ronaldo's kick, just pure chaos.

 I could not really findd the problem, before the controller the robot is okay, after the controller its more uncontrolled than before, I tried to change the controller settings and the parameters but there was no use, I have also 
 wrote about this issue in the discussion forums, but there is no response obviously.

 the only one who helped me was dr Zaki, my mentor for ros2, he changed the weights and the inertia, he also changed the diff_drive plugin limits, which I didnt really think of, and viola! it is working nice now! 

 the only thing remains for now is that when I open rviz2, it appears like the robot is there in two places at the same time, so it kind of glitches, I dont know the cause, but I will look into it. 

 okay, one thing I have figured out, when I initiate the controllers, the rviz robot starts tweaking out.

 in the video, he upgraded the robot to be the similar to the one in real life, but I grew attached to the current one and the I finaaally fixed everything with it, so I dont think I will changing it.

 okay, done, the problem was rviz was taking tfs at the same time, thus glitching. the solution is quite, turn off the odom tf in the controller yaml file.
 this is the command :      enable_odom_tf: false

 this will make things stable. 


 one more thing I have added, which is recording and listening to the position and the velocity of the joints when the simulation is running, this can be done in two ways. 
 before anything, the state broadcaster controller is not commented out anymore and thus is able to read the state of the joints.
 
 the first way is just listening to the data, this is done by listening, ros2 topic echo /joint_states 

 this will literally give you the live data for the robot. however it is not professional, as you can just listen. 

 the second way, is to use ros2bag to generate a file containing those data, ros2 bag record /joint_states /odom -o my_robot_data

 this will create the file "my_robot_data" and have the file of the joint_states in it. later on we can just convert to .csv or pdf.

most of the videos are for the hardware, like adding the joysticks and stuff, I am not going to watch it now tbh, but I will watch them later.

 now, it is time for the main dish for this big project, the nav2 and SLAM. 