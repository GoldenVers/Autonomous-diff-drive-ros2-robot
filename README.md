## ğŸ§  ROS2 Navigation & SLAM Simulation Project
This a journey of me following the tutorial of articulated robotics to create a mobile robot. this is here is a full ROS2-based mobile robot simulation project built with blood,sweat,tears, curiosity, and late-night bug hunting.

Note: please go to the latest branch for the latest code
Latest branch : nav2_and_slam



## PROJECT SUMMARY

â€¢ ğŸ› ï¸ **Simulation Framework**: Gazebo (Classic) for realistic physics and environment simulation  
â€¢ ğŸ§  **Middleware**: ROS2 Humble, utilizing ros2_control and Navigation2 stack  
â€¢ ğŸ—ºï¸ **SLAM & Navigation**: Integrated SLAM Toolbox for autonomous map creation and Nav2 for obstacle-aware goal planning  
â€¢ ğŸ§­ **Teleoperation**: Controlled wirelessly via keyboard, phone, or autonomous navigation  
â€¢ ğŸ‘€ **Sensors & Perception**: Equipped with LIDAR, RGB Camera, and Depth Cameraâ€”used for SLAM, vision, and obstacle detection  
â€¢ ğŸ”§ **Controllers**: Implemented diff_drive_controller with fine-tuned limits for stability and realistic robot movement as well as joint_state_broadcaster controller for sending the joints details, like the odometry and the velocity.
â€¢ ğŸ”„ **Transform Broadcasting**: Handled properly using tf2 and robot_state_publisher  
â€¢ ğŸ“¦ **Modular Architecture**: Built using URDF/XACRO and organized with launch files and config packages



## âŒ›Timeline of the project

âœ… Feb 2025: Initial URDF robot built and tested in Gazebo  
âœ… Mar 2025: Integrated ros2_control with diff_drive_controller  
âœ… Apr 2025: Implemented SLAM Toolbox and visualized data in RViz2  
âœ… May 2025: Deployed full Navigation2 stack with local and global planners  
âœ… Ongoing: Integration with camera and OpenCV for object detection


## ğŸ› ï¸ Project Overview
This project simulates a differential drive robot in a Gazebo world using ROS2 (Humble). The aim is to develop a simulated robot that can:

Be controlled via teleoperation or mobile input.
Use SLAM to build maps of unknown environments.
Navigate using Nav2 stack and autonomously move to goal positions.
Simulate real-world robotics behavior through Gazebo + RViz2.
## ğŸš€ Features
âœ… Differential drive simulation with ros2_control and gazebo_ros2_control
âœ… SLAM using slam_toolbox
âœ… Full integration with Nav2 stack
âœ… Twist multiplexer (twist_mux) for command management
âœ… Sensor TF broadcasting (camera, lidar, wheels, etc.)
âœ… RViz2 visualization
âœ… URDF and SDF modeling with a clean TF tree
âœ… Organized launch files for modularity
## ğŸ“¦ Tech Stack
Tech	Purpose
ROS2	Robotics Middleware Framework
Gazebo	Physics-based simulation environment
RViz2	3D visualization of robot state
ros2_control	Joint control and hardware abstraction
slam_toolbox	Online and offline SLAM
Nav2	Navigation stack for path planning
URDF/SDF	Robot modeling
## ğŸ“ˆ Project Journey
This project WAS NOT smooth, but it was worth every challenge.

## ğŸ‘¨â€ğŸ« Started by building a custom robot URDF.
ğŸ”§ Debugged endless issues with diff_drive_controller & wheel joints.
ğŸ“Š Used view_frames to troubleshoot TF conflicts.
ğŸ§™â€â™‚ï¸ The breakthrough came after tweaking robot inertial parameters and plugin tuning.
ğŸ’¡ Realized RViz2 glitching was due to duplicated odom TFâ€”disabled it manually and voilÃ ! ğŸ‰
ğŸ”€ Branching out via Git for every phase.
ğŸ§­ SLAM started mapping magic after carefully configuring the sensors and slam_toolbox.
ğŸ§© Learned to carefully manage twist_mux parameters and params.yaml structure.
ğŸ§¹ Cleaned up launches and got Nav2 running with simulation time syncing.
ğŸ¥³ Final Status
The robot is now successfully able to:

Map its environment in real time.
Navigate to a defined goal using Nav2.
Accept multiple input commands using a multiplexer.
Broadcast all necessary TFs without conflict.
And all of this... without physical hardware.
Powered by: Sweat, bugs, and robot dreams ğŸ¤–
## ğŸ“ How to Run
Make sure to build the workspace and source the overlay before launching!

cd ~/ros2_ws
colcon build --symlink-install
source install/setup.bash



## Looking ahead

ğŸš€ Next Phase: Object Detection + Robotic Arm Integration with UR10 using MoveIt2 and OpenCV  
ğŸ¤ Open to internship collaborations and robotics research opportunities  
